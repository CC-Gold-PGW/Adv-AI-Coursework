{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "# helper to load data from PNG image files# helpe \n",
    "import imageio\n",
    "# glob helps select multiple files using patterns\n",
    "import glob\n",
    "# helps to manipulate the image for rotation \n",
    "from scipy import ndimage\n",
    "import pandas as pd # to manage data frames and reading csv files\n",
    "import numpy as np\n",
    "#for the sigmoid function we need expit() from scipy\n",
    "import scipy.special\n",
    "#library for plotting arrays\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# A particularly interesting backend, provided by IPython, is the inline backend. \n",
    "# This is available only for the Jupyter Notebook and the Jupyter QtConsole. \n",
    "# It can be invoked as follows: %matplotlib inline\n",
    "# With this backend, the output of plotting commands is displayed inline \n",
    "# within frontends like the Jupyter notebook, directly below the code cell that produced it. \n",
    "# The resulting plots are inside this notebook, not an external window.\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# datasets to read\n",
    "# you can change these when trying out other datasets\n",
    "train_file = \"mnist_train.csv\"\n",
    "test_file = \"mnist_test.csv\"\n",
    "\n",
    "\n",
    "#read the file into a pandas frame\n",
    "df = pd.read_csv(train_file, header=None) \n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df_orig_train = pd.read_csv(train_file, header=None)  # read entire train dataset\n",
    "df_orig_test = pd.read_csv(test_file, header=None)  # read entire test dataset\n",
    "df_orig_train.info()\n",
    "\n",
    "y_train_all =  pd.get_dummies(df_orig_train[0]).values\n",
    "X_train_all = df_orig_train.drop(0, axis = 1).values\n",
    "#print(y_train_all.shape)\n",
    "#print(X_train_all.shape)\n",
    "\n",
    "y_test_all =  pd.get_dummies(df_orig_test[0]).values\n",
    "X_test_all = df_orig_test.drop(0, axis = 1).values\n",
    "#print(y_test_all.shape)\n",
    "#print(X_test_all.shape)\n",
    "\n",
    "\n",
    "# Select smaller samples of the train and test datasets (will execute faster when training our networks than using the entire dataset)\n",
    "train_sample_size = 1500  # choosing a smaller sample instead of the entire dataset\n",
    "random_indices = np.random.choice(range(len(y_train_all)), train_sample_size, replace = False)\n",
    "\n",
    "X_train = X_train_all[random_indices]\n",
    "y_train = y_train_all[random_indices]\n",
    "#print(y_train.shape)\n",
    "#print(X_train.shape)\n",
    "\n",
    "#preprocessing steps\n",
    "X_train = (X_train / 255.0 * 0.99) + 0.01\n",
    "y_train = y_train + 0.01\n",
    "y_train = np.where(y_train != 1.01, y_train, 0.99)\n",
    "#print(y_train.shape)\n",
    "\n",
    "test_sample_size = 100 \n",
    "random_test_indices = np.random.choice(range(len(y_test_all)), test_sample_size, replace = False)\n",
    "X_test = X_test_all[random_test_indices]\n",
    "y_test = y_test_all[random_test_indices]\n",
    "#print(y_test.shape)\n",
    "#print(X_test.shape)\n",
    "\n",
    "X_test = (X_test / 255.0 * 0.99) + 0.01\n",
    "y_test = y_test + 0.01\n",
    "y_test = np.where(y_test != 1.01, y_test, 0.99)\n",
    "\n",
    "\n",
    "def mean_squared_error(predictions, targets):\n",
    "    \"\"\"\n",
    "    Calculates mean squared error of a model's predictions.\n",
    "    \"\"\"\n",
    "    N=targets.size\n",
    "    mse = ((targets - predictions) **2).sum() / (2*N)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of a model's predictions.\n",
    "    \"\"\"\n",
    "    prediction_labels = np.argmax(predictions, axis=1)\n",
    "    target_labels = np.argmax(targets, axis=1)\n",
    "    predictions_correct = (prediction_labels == target_labels.round())\n",
    "    accuracy = predictions_correct.mean()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)\n",
    "    def backward(self, inputs):\n",
    "        self.output = np.greater(inputs, 0).astype(int) # inputs > 0 then convert bools to int\n",
    "        \n",
    "class Activation_Sigmoid:\n",
    "    def forward(self, x):\n",
    "        return(1 / (1 + np.exp(-x)))\n",
    "    def backward(self, x):\n",
    "        return(x * ( 1 - x))\n",
    "    \n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons, learningrate=0.01, activation='sigmoid'):\n",
    "        \n",
    "        self.weights = np.random.normal(0.0, pow(n_inputs, -0.5), (n_inputs, n_neurons))\n",
    "        #print(self.weights.shape)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "       \n",
    "        self.lr = learningrate\n",
    "        self.activate=activation  \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        self.in_values = inputs\n",
    "        self.layer_input = np.dot(inputs , self.weights) + self.biases\n",
    "        self.activation()\n",
    "    \n",
    "    def activation(self):\n",
    "        if self.activate == 'sigmoid':\n",
    "            a = Activation_Sigmoid()\n",
    "            self.layer_output = a.forward(self.layer_input)\n",
    "            \n",
    "           \n",
    "    def del_activation(self):\n",
    "        if self.activate == 'sigmoid':\n",
    "            del_a = Activation_Sigmoid()\n",
    "            self.del_layer_output =  del_a.backward(del_a.forward(self.layer_input))\n",
    "      \n",
    "    def backward(self, delta_in, weights_in, targets=None, output_layer=False):\n",
    "        self.del_activation()\n",
    "        if output_layer:\n",
    "            self.layer_error = self.layer_output - targets\n",
    "            self.layer_delta = self.layer_error * self.del_layer_output\n",
    "        else:          \n",
    "            self.layer_error = np.dot(delta_in, weights_in.T)\n",
    "            self.layer_delta = self.layer_error * self.del_layer_output\n",
    "        \n",
    "    def weight_update(self, prev_layer_output):\n",
    "        # print(\"prev_layer_output.T.shape: \"+str(prev_layer_output.T.shape))\n",
    "        # print(\"self.layer_delta.shape: \"+str(self.layer_delta.shape))\n",
    "        N = self.layer_delta.shape[0]\n",
    "        weights_update = np.dot(prev_layer_output.T, self.layer_delta) / N\n",
    "        # print(weights_update.shape)\n",
    "        self.weights -= self.lr * weights_update\n",
    "        biases_update = np.mean(self.layer_delta, axis=0, keepdims=True)\n",
    "        # print(\"biases_update.shape: \"+ str(biases_update.shape))\n",
    "        # print(\"self.biases.shape: \"+ str(self.biases.shape))\n",
    "        self.biases -= self.lr * biases_update\n",
    "\n",
    "\n",
    "class ANN():\n",
    "    def __init__(self, ouput_layer, hidden_layer, batch_size = 10):\n",
    "        self.output = ouput_layer\n",
    "        self.layer1 = hidden_layer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def batch_input(self, x, y):\n",
    "        for i in range(0, len(x), self.batch_size):\n",
    "            yield (x[i:i + self.batch_size], y[i:i + self.batch_size])\n",
    "\n",
    "    def train(self, x, y, epochs, lr):\n",
    "        self.layer1.lr = lr\n",
    "        self.output.lr = lr\n",
    "\n",
    "        monitoring = {}\n",
    "        monitoring['mean_squared_error'] = []\n",
    "        monitoring['accuracy'] = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for (batch_x, batch_y) in self.batch_input(x, y):\n",
    "                self.layer1.forward(batch_x)\n",
    "                #print('layer1 output \\n' ,layer1.layer_output.shape)\n",
    "                self.output.forward(self.layer1.layer_output)\n",
    "                # print('layer output  \\n', output.layer_output.shape)\n",
    "\n",
    "                # backprop through the layers \n",
    "                self.output.backward(None, None, batch_y, True)\n",
    "                # print('layer out delta  \\n', output.layer_delta.shape)\n",
    "                self.layer1.backward(self.output.layer_delta, self.output.weights)\n",
    "                # print('layer1 delta  \\n', layer1.layer_delta.shape)\n",
    "\n",
    "                # update all the layer weights\n",
    "                self.output.weight_update(self.layer1.layer_output)\n",
    "                # print('layer weights  \\n', output.weights.shape)\n",
    "                self.layer1.weight_update(batch_x)\n",
    "                # print('layer weights  \\n', layer1.weights.shape)\n",
    "            pred = self.predict(x)\n",
    "            mse, acc = self.evaluate(pred, y)\n",
    "            monitoring['mean_squared_error'].append(mse)\n",
    "            monitoring['accuracy'].append(acc)\n",
    "\n",
    "        monitoring_df = pd.DataFrame(monitoring)   \n",
    "        return monitoring_df\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.layer1.forward(x)\n",
    "        self.output.forward(self.layer1.layer_output)\n",
    "        return self.output.layer_output\n",
    "\n",
    "    def evaluate(self, predicts, y):\n",
    "        mse = mean_squared_error(predicts, y)\n",
    "        acc = accuracy(predicts, y)\n",
    "        return mse, acc\n",
    "\n",
    "    def test(self, x, y):\n",
    "        monitoring = {}\n",
    "        pred = self.predict(x)\n",
    "        mse, acc = self.evaluate(pred, y)\n",
    "        monitoring['mean_squared_error'] = [mse]\n",
    "        monitoring['accuracy'] = [acc]\n",
    "        return pd.DataFrame(monitoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(inputs, degree):\n",
    "  \n",
    "    ## create rotated variations\n",
    "    # rotated anticlockwise by x degrees\n",
    "    inputs_plusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), degree, cval=0.01, order=1, reshape=False)\n",
    "    new_inputs1 = inputs_plusx_img.reshape(784)\n",
    "    # rotated clockwise by x degrees\n",
    "    inputs_minusx_img = scipy.ndimage.interpolation.rotate(inputs.reshape(28,28), -degree, cval=0.01, order=1, reshape=False)\n",
    "    new_inputs2 = inputs_minusx_img.reshape(784)\n",
    "    \n",
    "    return (new_inputs1, new_inputs2)\n",
    "\n",
    "def dataset_rotate_augment(image, degree=30):\n",
    "    #print(instance.reshape(28,28))\n",
    "    new_image1, new_image2 = rotate_image(image, degree)\n",
    "    # show rotated image\n",
    "    image_array = np.asfarray(new_image1).flatten().reshape((28,28))\n",
    "    \n",
    "    # # print the grid in grey scale\n",
    "    # plt.imshow(image_array, cmap='Greys', interpolation='None') "
   ]
  }
 ]
}